{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data Mining\n",
    "## Practical Assignment 3\n",
    "\n",
    "### Important Notes:\n",
    "1. Submit through **Blackboard** in electronic form before 11:59pm on Wednesday, May 31, 2017\n",
    "2. No late homework will be accepted.\n",
    "3. This is a group-of-three assignment; hence choose two partner to work with.\n",
    "4. The submitted file should be in ipynb format\n",
    "5. The file should be submitted by all students in the group.\n",
    "6. The assignment is worth it 10 points\n",
    "7. For questions, please use [Piazza](http://piazza.com/university_of_amsterdam/spring2017/5072dami6y) (English only!)\n",
    "8. The indication **optional** means that the question is optional; you won't lose any points if you do not do that part of the assignment, nor will you gain if you do it.\n",
    "\n",
    "### Software:\n",
    "We will be using Python programming language throughout this course. Further we will be using:\n",
    "+ IPython Notebooks (as an environment)\n",
    "+ Numpy\n",
    "+ Pandas\n",
    "+ Scikit-learn\n",
    "\n",
    "\n",
    "### Background:\n",
    "\n",
    "This practical assignment will be covering clustering and working with text. \n",
    "\n",
    "For the assignment, please download the dataset on [Movies](https://drive.google.com/drive/folders/0B-zklbckv9CHMmhzSXRPMk9tSWs?usp=sharing).\n",
    "\n",
    "The folder contains two data files and a README file. Both data files, plot_summaries.txt and movie.metadata.tsv are tab separated files. The former, i.e. plot_summaries.txt, contains the plot summaries of 42,306 movies extracted from the November 2, 2012 dump of English-language Wikipedia. Each line contains the Wikipedia movie ID (which indexes into movie.metadata.tsv) followed by the summary. The latter file, i.e. movie.metadata.tsv contains metadata for 81,741 movies, extracted from the Noverber 4, 2012 dump of Freebase. Freebase is a knowledge base (similar to a database) that contains information about different Entities (including movies). The file is tab-separated with the following columns:\n",
    "\n",
    "1. Wikipedia movie ID\n",
    "2. Freebase movie ID\n",
    "3. Movie name\n",
    "4. Movie release date\n",
    "5. Movie box office revenue\n",
    "6. Movie runtime\n",
    "7. Movie languages (Freebase ID:name tuples)\n",
    "8. Movie countries (Freebase ID:name tuples)\n",
    "9. Movie genres (Freebase ID:name tuples)\n",
    "\n",
    "The goal of this assignment will be to cluster movies.\n",
    "\n",
    "**Important Note**: This third assignment is not as instructive as the first assignment. The first assignment guided you step-by-step through all the preprocessing, training-validation-testing setup, etc. This assignment does not do so, but it leaves it up to you to decide how to use the data and design your experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Part 1: Import the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We import both files and performing a join (merging the two files) using the Wikipedia ID (WID) to match the movies that appear in summaries to those that appear in the metadata. If a movie does not appear in either file, it is not included in the final list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "metadata = pd.read_csv('MovieSummaries/movie.metadata.tsv',sep=\"\\t\", header = None,\n",
    "                        names=['WID', 'FID', 'Name', 'Release', 'Revenue', \n",
    "                               'Runtime', 'Languages', 'Countries', 'Genres'])\n",
    "summaries = pd.read_csv('MovieSummaries/plot_summaries.txt',sep=\"\\t\", header = None,\n",
    "                         names=['WID', 'Text'])\n",
    "films = pd.merge(metadata, summaries, on='WID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A movie can be have more than one genre. We extract the first genre that characterizes the movie. Some movies may not have any corresponing genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "genres = []\n",
    "for film in films.values:\n",
    "    exist = False\n",
    "    g = ast.literal_eval(film[8])\n",
    "    # Get the first genre for this movie\n",
    "    for key in g:\n",
    "        exist = True\n",
    "        genres.append(g[key])\n",
    "        break\n",
    "    # If there is no genre for this movie\n",
    "    if exist is False:\n",
    "        genres.append('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Consider only movies in four genres: 'Drama', 'Comedy', 'Science Fiction', 'Action'. Then sort them by Revenue they had in the cinemas, and get the top 100 most popular ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Merge the films with the genre into a single Dataframe\n",
    "genres = pd.Series(genres, name='Genre')\n",
    "films_genre = pd.concat([films, genres], axis=1)\n",
    "\n",
    "# Get only movies about the four following genres\n",
    "films_genre_ind = films_genre.set_index('Genre')\n",
    "movie_genres = ['Drama', 'Comedy', 'Science Fiction', 'Action']\n",
    "genre100 = pd.DataFrame()\n",
    "for mg in movie_genres:\n",
    "    genre100 = genre100.append(films_genre_ind.ix[mg])\n",
    "\n",
    "# Get the top-100 of those\n",
    "top100 = (genre100.sort_values(by='Revenue',ascending=False)[0:100]).reset_index()[['Name','Text','Genre']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drama              45\n",
      "Comedy             32\n",
      "Science Fiction    12\n",
      "Action             11\n",
      "Name: Genre, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Look at the distribution of your movies in the dataset\n",
    "print(top100['Genre'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Part 2: Turn movies into BoW and Topics representation (Lecture 7) (5pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Turn each movie plot summary (i.e. the 'Text' column in the top100 dataframe) into:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = top100['Text'].asobject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* **Bag-of-Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def BagOfWords(documents):\n",
    "    vect = CountVectorizer(analyzer=\"word\",\n",
    "                          stop_words=None)\n",
    "    return vect.fit_transform(documents)\n",
    "\n",
    "bow = BagOfWords(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* **Bag-of-bigrams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def BagOfBigrams(documents):\n",
    "    vect = CountVectorizer(ngram_range=(2,2),\n",
    "                           analyzer=\"word\",\n",
    "                          stop_words=None)\n",
    "    return vect.fit_transform(documents)\n",
    "\n",
    "bo2g = BagOfBigrams(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* **Bag-of-ngrams (for n = 1 and 2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def BagOfNgrams(documents, n=1):\n",
    "    vect = CountVectorizer(ngram_range=(n,n),\n",
    "                           analyzer=\"word\",\n",
    "                          stop_words=None)\n",
    "    return vect.fit_transform(documents)\n",
    "\n",
    "bo12g = BagOfNgrams(documents, n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* **TF-IDF values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tfidf(documents):    \n",
    "    tfidf = TfidfVectorizer(norm=None).fit(documents)\n",
    "    return tfidf.fit_transform(documents)\n",
    "\n",
    "tfidf = tfidf(documents)\n",
    "# print(tfidf.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* **Topics**\n",
    "    * Experiment with different number of topics and choose the one that satisfies you by inspecting the top-10 most important words in each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "topics = # your code goes here\n",
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Part 3: Clustering (Lecture 6) (5pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Cluster the movies using the k-means algorithm.\n",
    "\n",
    "**Important Note**: In order to allow you to work on Part 3, before Part 2, the [Movies](https://drive.google.com/open?id=0B-zklbckv9CHcUtwcWxTTjlvcHc) folder also contains a comma-separated file that includes a representation I built for you for the movies plot summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### k-means\n",
    "\n",
    "+ Choose the number of ~~topics~~ clusters you wish to find in the data (n_clusters)\n",
    "+ Choose a text representation from Part 2\n",
    "+ Run a k-means algorithm\n",
    "+ Evaluate the quality of the algorithm using inertia_, silhouette_score, adjusted_mutual_info_score, and adjusted_rand_score\n",
    "    + silhouette_score, adjusted_mutual_info_score require the ground truth\n",
    "    + use as ground truth the genre of each movie, i.e. the perfect clustering would be the one that clusters movies based on their genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** number of cluster **\n",
    "\n",
    "* Change the value of n\\_clusters and plot inertia_, silhouette_score, adjusted_mutual_info_score, and adjusted_rand_score as a function of n_clusters\n",
    "* Explain what you observe in the plots.\n",
    "* Do the same for each text representation from Part 2.\n",
    "* Explain the differences across different representations if there are any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "*your explanations go here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** demonstrate clusters **\n",
    "\n",
    "* for each representation choose the optimal number of clusters and repeat the k-means algorithm for that number of clusters\n",
    "* print the top-10 most important words within each cluster\n",
    "* print the titles of the movies for each cluster\n",
    "* explain what you observe and whether results make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* your explanations go here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
